{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111121c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROVARE A FARE FUNZIONE DA RUNNARE IN BASE ALL'ULTIMO CAPITOLO SALVATO (come per progetto negozi)\n",
    "\n",
    "#potenziali (cercarne altre): \n",
    "\n",
    "    \n",
    "#il problema è che aggiorna capitolo a  [\\s]1 e quindi anche eg. 1 tonnellata; 1 anno ecc..\n",
    "folder='bibles/'\n",
    "testi=['Unlocked Literal Bible__.pdf', #OK\n",
    "        'Easy-to-Read Version__American.pdf',  #problema titoli (dati capitolo C e verso v, e rispetto al capitolo seguente, il capitolo rimane i-1 ma v<<v-1 )\n",
    "       \"Young's Literal Translation__archaic British.pdf\",\n",
    "      \"JPS TaNaKH 1917__American.pdf\", #(jewish bible)\n",
    "       \"Revised Version with Apocrypha (1895)__archaic British\",\n",
    "       \"Noah Webster Bible__archaic American\",\n",
    "       \"King James (Authorized) Version__archaic British\",\n",
    "       \"Open English Bible (Commonwealth Spelling)__\",\n",
    "       \"Open English Bible (U. S. spelling)__\",\n",
    "       \"Targum Onkelos Etheridge__\"\n",
    "       \n",
    "      ]\n",
    "file_="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def write_csv(dict_,filename,chapter):\n",
    "    keys_=[]\n",
    "    values_=[]\n",
    "    for item in dict_.items():\n",
    "        for val in item[1]:\n",
    "            for verse in val:\n",
    "                keys_.append(item[0])\n",
    "                values_.append(verse)\n",
    "    print(keys_,values_)\n",
    "    df=pd.DataFrame(columns=['Chapter','Verses'])\n",
    "    df['Chapter']=keys_\n",
    "    df['Verses']=values_\n",
    "    df.to_csv('csv bibles/'+filename.replace('.pdf','')+';'+chapter+'.csv',index=False,header=True)\n",
    "    return df\n",
    "#write_csv(temp_chapter_dict,'file','Genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33294e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NON ELIMINA NOTE A PIE DI PAGINA E TITOLI DI SEZIONI(rintracciabili da anomalie nell'indice <cap:verso>)\n",
    "#FUNZIONA CON PDF SENZA COLONNE (nè nella prefazione, nè nel resto)\n",
    "#FUNZIONA CON PDF CON 1:1 AL PRIMO CAPITOLO (skippa prefazione)\n",
    "\n",
    "for f,file in enumerate(os.listdir(folder)): #eliminare ciclo for\n",
    "    temp_chapter_dict={}\n",
    "    pdf = pdfplumber.open(f'bibles/{file_}')\n",
    "    index_=\"\"\"\"\"\"\n",
    "    idxs_pages=[]\n",
    "    roman_nums=['i','ii','iii','v','vi','vii','viii','ix','x']\n",
    "    target_rem=0\n",
    "    for i,page in enumerate(tqdm(pdf.pages)):\n",
    "        if 'content' in page.extract_text(x_tolerance=1) or ' . . . . ' in page.extract_text(x_tolerance=1):\n",
    "            index_+=page.extract_text(x_tolerance=1)\n",
    "            idxs_pages.append(i)\n",
    "        elif '1:1' in page.extract_text(x_tolerance=1):\n",
    "            target_rem=i\n",
    "            break\n",
    "        #any([x in 'a' for x in roman_nums ])\n",
    "        #if i>=10:\n",
    "            #break\n",
    "    index_='\\n'.join([x for x in index_.split('\\n') if '.' in x])\n",
    "    print(index_)\n",
    "    index_=index_.split('\\n')\n",
    "    print(index_)\n",
    "    #index_=[ x.split('.')[:-1] + ' ' + x.split('.')[-1].strip() for x in index_]\n",
    "    #print('SORTED',sorted(index_,key= lambda x:int(x.strip().split(' ')[-1])))\n",
    "    index_=[''.join(x.split('.')).strip() for x in index_]\n",
    "    index_=[ x.split('    ')[0] + '    ' + x.split('    ')[-1].strip() for x in index_]#index_=[ + ' ' + x.split('.')[-1].strip() for x in index_]\n",
    "    \n",
    "    pages_=pdf.pages[target_rem:] #skip preface\n",
    "    page_numbers=[x for x in range(target_rem,len(pages_)+1)]\n",
    "    cap=0\n",
    "    #already_seen_idx=[] #check if next chap to reset curr_cap\n",
    "    already_seen_idx=[x.split(';')[-1].replace('.csv','') for x in os.listdir('csv bibles/')]\n",
    "    check_list=[x for x in os.listdir('csv bibles/')]\n",
    "    #for i,idx in enumerate(tqdm(clean_idx)):\n",
    "        #clean_idx=' '.join(index_[i].split(' ')[:-1]).strip()\n",
    "        #if\n",
    "    #print('PAGE NUMBERS',page_numbers)\n",
    "    for j,p in enumerate(pages_):\n",
    "                page_=pages_[j].extract_text(x_tolerance=1)\n",
    "                page_chapter=re.match(r'([\\d]?[\\s]?[A-z\\s]+[\\D])',page_) #([\\d]?[\\s]?[A-z]+[\\D]) #OLD, NON PRENDE TITOLI CON SPAZI\n",
    "                clean_idx=page_[page_chapter.start():page_chapter.end()].strip()\n",
    "                if any([clean_idx.strip() in x for x in check_list]):\n",
    "                    print('SKIPPING',clean_idx)\n",
    "                    continue\n",
    "                if already_seen_idx==[]: #to not launch error on [-1]\n",
    "                    already_seen_idx.append(clean_idx)\n",
    "                if clean_idx != already_seen_idx[-1]: #or j==len(pages_)-1\n",
    "                    cap=0\n",
    "                    file_name=str(already_seen_idx.index(already_seen_idx[-1])+1)+'-'+file_\n",
    "                    #write_csv(target_idx=already_seen_idx[-1], new_data=temp_chapter_dict) #try to free memory at each chapter\n",
    "                    write_csv(temp_chapter_dict,file_name,already_seen_idx[-1])\n",
    "                    del temp_chapter_dict\n",
    "                    temp_chapter_dict={}\n",
    "                    \n",
    "                if clean_idx not in already_seen_idx:\n",
    "                    already_seen_idx.append(clean_idx)\n",
    "                    \n",
    "                print('ALREADY SEEN', already_seen_idx)\n",
    "                #remove bottom page\n",
    "                flag_no_num_line=False\n",
    "                if re.search(r'([\\s][\\d]+:[\\d]+)','\\n'.join(page_.split('\\n')[1:])):\n",
    "                    print('FOUND')\n",
    "                    temp_page_='\\n'.join(page_.split('\\n')[1:])\n",
    "                    try:\n",
    "                        temp_page_=temp_page_[:re.search(r'([\\s][\\d]+:[\\d]+)',temp_page_).span()[0]] #remove elements at the end having <symbol\\s\\d:                \n",
    "                        page_=temp_page_\n",
    "                        flag_no_num_line=True\n",
    "                    except Exception as e:\n",
    "                        print('errore ',j,e)\n",
    "                print('PAGE',page_)\n",
    "                print('P Chap',clean_idx)\n",
    "                nlp=spacy.load('en_core_web_sm')\n",
    "                nlp.max_length=1500000\n",
    "                #limit=len(text_)/10\n",
    "                nlp.add_pipe('sentencizer')\n",
    "                doc=nlp(page_,disable = ['ner', 'parser'])\n",
    "                #tokens_=[x.text for x in doc]\n",
    "                \n",
    "                if flag_no_num_line==False:\n",
    "                    text_for_chapt='\\n'.join(doc.text.split('\\n')[1:])\n",
    "                    text_='\\n'.join(doc.text.split('\\n')[1:])\n",
    "                elif flag_no_num_line==True:\n",
    "                    text_for_chapt='\\n'.join(doc.text.split('\\n'))\n",
    "                    text_='\\n'.join(doc.text.split('\\n'))\n",
    "\n",
    "                matches_=[]\n",
    "                caps_=[]\n",
    "                prev_page=pages_[j].page_number\n",
    "                no_number_line=re.match('(^[\\D]+)',text_)\n",
    "                no_number_line_res=''\n",
    "                #check if initial line without number\n",
    "\n",
    "                if no_number_line:\n",
    "                    no_number_line_res+=text_[no_number_line.start():no_number_line.end()]\n",
    "                    print('NO NUMBER', no_number_line_res)\n",
    "                    try:\n",
    "                        temp_chapter_dict[clean_idx]\n",
    "                    except:\n",
    "                        temp_chapter_dict[clean_idx]=[['']]\n",
    "                    #if len(temp_chapter_dict[clean_idx])>0:\n",
    "                    try:\n",
    "                        temp_chapter_dict[clean_idx][-1][-1]+=' '+no_number_line_res.replace('\\n','')\n",
    "                    except:\n",
    "                        temp_chapter_dict[clean_idx].append(' '+no_number_line_res.replace('\\n',''))\n",
    "\n",
    "                match_chapters=re.finditer('(^[\\d]+[\\\\n])',text_)\n",
    "                print('MATCH CHAP LIST',match_chapters)\n",
    "                #temp_curr_cap=0 #assegna capitolo precedente a ultima riga capitolo ch\n",
    "                for m_,match in enumerate(re.finditer('([\\d]+[\\\\n])',text_)):\n",
    "                    print('CHAP',match)\n",
    "                    if text_[match.start():match.end()].endswith('\\n')\\\n",
    "                      and text_[match.start():match.end()][0].isnumeric():\n",
    "                      #and m_!=0:\n",
    "                        curr_cap=text_[match.start():match.end()].replace('\\n','') #chapter line\n",
    "                        \n",
    "                        print('IN',curr_cap)\n",
    "                        \n",
    "                match_lines=[x for x in re.finditer(r'(?<!:)([\\d]+-?[^:])[\\s]?[A-Za-z\"“”]',text_)]\n",
    "                for m_,match in enumerate(re.finditer(r'(?<!:)([\\d]+-?[^:])[\\s]?[A-Za-z\"“”]',text_)): #old pattern ([\\\\n]?[\\d]{1,}?)[^:]                  \n",
    "                    matches_.append(match.span())\n",
    "                    target_=text_[match.start():match.end()]\n",
    "                    \n",
    "                    #if int(target_.strip().split(' ')[0])>1 and curr_cap!=1\\\n",
    "                    #and int(next_target_.strip().split(' ')[0])==1:#\n",
    "                    #    curr_cap=str(int(curr_cap)-1)\n",
    "                    #    caps_.append(int(curr_cap.strip()))\n",
    "                    #else:\n",
    "                    #    caps_.append(curr_cap)\n",
    "                clean_lines=[]\n",
    "                for i,each in enumerate(matches_):\n",
    "                    if i+1<len(matches_):\n",
    "                        #print(text_[each[0]:matches_[i+1][0]])\n",
    "                        target_=text_[each[0]:matches_[i+1][0]]\n",
    "                        if re.match('(^[1][\\D][^:])\\D',target_):\n",
    "                            cap+=1\n",
    "                        print(target_)\n",
    "                        clean_lines.append(str(cap).replace('\\n','')+':'+target_.replace('\\n',' '))\n",
    "                    else: #last line of the page\n",
    "                        print('LAST LINE',text_[each[0]:])\n",
    "                        target_=text_[each[0]:]\n",
    "                        if re.match('(^[1][\\D][^:])\\D',target_):\n",
    "                            cap+=1\n",
    "                        #                      caps_[i]\n",
    "                        print(target_)\n",
    "                        clean_lines.append(str(cap).replace('\\n','')+':'+target_.replace('\\n',' '))\n",
    "                try:\n",
    "                    temp_chapter_dict[clean_idx].append(clean_lines)\n",
    "                except:\n",
    "                    temp_chapter_dict[clean_idx]=[]\n",
    "                    temp_chapter_dict[clean_idx].append(clean_lines)\n",
    "                \n",
    "    #if j==len(pages_)-1: #save if end of the last page\n",
    "    cap=0\n",
    "    file_name=str(already_seen_idx.index(clean_idx)+1)+'-'+file_\n",
    "    #write_csv(target_idx=already_seen_idx[-1], new_data=temp_chapter_dict) #try to free memory at each chapter\n",
    "    write_csv(temp_chapter_dict,file_name,clean_idx)\n",
    "    del temp_chapter_dict\n",
    "    temp_chapter_dict={}\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
